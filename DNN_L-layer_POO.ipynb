{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset:\n",
    "    \"\"\" create the 2 XOR datasets, X & Y, for the DNN model \"\"\"\n",
    "    \n",
    "    # create the entry dataset X\n",
    "    def create_X(self, X_size):\n",
    "        self.X = np.random.randint(2, size=(2, X_size))\n",
    "        return self.X\n",
    "    \n",
    "    # create the label dataset Y\n",
    "    def create_Y(self, X, X_size):\n",
    "        self.Y = np.sum(X, axis=0).reshape((1,X_size))\n",
    "        self.Y[self.Y != 1] = 0\n",
    "        return self.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    \"\"\" the abstract class for all activation funtion classes\"\"\"\n",
    "    \n",
    "    # the basic formula of the activation function for the forward pass\n",
    "    def formula(self, Z):\n",
    "        raise NotImplementdError\n",
    "    \n",
    "    # to calculate the derivative of the activation function for the backward pass\n",
    "    def derivative(self, input):\n",
    "        raise NotImplementdError\n",
    "    \n",
    "    # to be used to finetune the initialized weight according to the activation function set for the first layer\n",
    "    def heuristic(self, layer_b4):\n",
    "        raise NotImplementdError\n",
    "    \n",
    "\n",
    "class Sigmoid(Activation):\n",
    "    \"\"\" all the functions related to the sigmoid activation function \"\"\"\n",
    "    \n",
    "    # the basic formula of the sigmoid function for the forward pass\n",
    "    def formula(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    # to calculate the derivative of the sigmoid function for the backward pass\n",
    "    def derivative(self, A):\n",
    "        return A * (1 - A)\n",
    "    \n",
    "    # to be used to finetune the initialized weight if sigmoid function is set for the first layer\n",
    "    def heuristic(self, layer_b4):\n",
    "        return np.sqrt(1 / layer_b4)\n",
    "    \n",
    "\n",
    "class Tanh(Activation):\n",
    "    \"\"\" all the functions related to the tanh activation function \"\"\"\n",
    "    \n",
    "    # the basic formula of the tanh function for the forward pass\n",
    "    def formula(self, Z):\n",
    "        return (np.exp(Z) - np.exp(-Z)) / (np.exp(Z) + np.exp(-Z))\n",
    "    \n",
    "    # to calculate the derivative of the tanh function for the backward pass\n",
    "    def derivative(self, A):\n",
    "        return 1 - A**2\n",
    "    \n",
    "    # to be used to finetune the initialized weight if tanh function is set for the first layer\n",
    "    def heuristic(self, layer_b4):\n",
    "        return np.sqrt(1 / layer_b4)\n",
    "    \n",
    "    \n",
    "class Relu(Activation):\n",
    "    \"\"\" all the functions related to the relu activation function \"\"\"\n",
    "    \n",
    "    # the basic formula of the relu function for the forward pass\n",
    "    def formula(self, Z):\n",
    "        return (Z > 0) * Z\n",
    "    \n",
    "    # to calculate the derivative of the relu function for the backward pass\n",
    "    def derivative(self, Z):\n",
    "        return (Z > 0) * 1\n",
    "    \n",
    "    # to be used to finetune the initialized weight if relu function is set for the first layer\n",
    "    def heuristic(self, layer_b4):\n",
    "        return np.sqrt(2 / layer_b4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cost:\n",
    "    \"\"\" the abstract class for all the cost functions \"\"\"\n",
    "    \n",
    "    # calculate the cost function\n",
    "    def formula(self, A, Y):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    # calculate the derivative of the cost function (dA[L]) for the last layer\n",
    "    def derivative(self, A, Y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class LossEntropy(Cost):\n",
    "    \"\"\" Use Loss Entropy to calculate the cost \"\"\"\n",
    "    \n",
    "    # calculate the Lose Entropy cost\n",
    "    def formula(self, A, Y):\n",
    "        self.m = Y.shape[1]\n",
    "        return - np.sum((Y * np.log(A) + (1-Y) * np.log(1-A)), axis=1) / self.m\n",
    "    \n",
    "    # calculate the derivative of the Lost Entropy cost\n",
    "    def derivative(self, A, Y):\n",
    "        return - ((np.divide(Y, A)) - (np.divide(1-Y, 1-A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\" the abstract class for all layer classes \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # implement forward pass\n",
    "    def forward_pass(self, input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    # implement backward pass\n",
    "    def backward_pass(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "class FCLayer(Layer):\n",
    "    \n",
    "    # initialize parameters\n",
    "    def __init__(self, layer_b4, layer_after, activation):\n",
    "\n",
    "        self.activation = activation\n",
    "        self.W = np.random.randn(layer_after, layer_b4) * getattr(self.activation, 'heuristic')(self, layer_b4)\n",
    "        self.b = np.zeros((layer_after, 1))\n",
    "    \n",
    "    # calculate forward pass: linear fn (Z = WX + b) and non-linear (A = g(Z))\n",
    "    def forward_pass(self, X):\n",
    "        self.A_prev = X\n",
    "        self.Z = np.dot(self.W, X) + self.b\n",
    "        self.A = getattr(self.activation, 'formula')(self, self.Z)\n",
    "        return self.A\n",
    "    \n",
    "    # calculate backward pass: \n",
    "    # dZ = dA * g'(Z))\n",
    "    # dA[l-1] = W.T * dZ\n",
    "    def backward_pass(self, dA, learning_rate):\n",
    "        self.m = dA.shape[1]\n",
    "        \n",
    "        self.dZ = dA * getattr(self.activation, 'derivative')(self, self.A)\n",
    "        pre = np.dot(self.W.T, self.dZ)\n",
    "        \n",
    "        self.dW = np.dot(self.dZ, self.A_prev.T) / self.m        \n",
    "        \n",
    "        self.W -= learning_rate * self.dW\n",
    "        self.b -= learning_rate * (np.sum(self.dZ) / self.m)\n",
    "        \n",
    "        return np.dot(self.W.T, self.dZ) # dA[l-1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \"\"\" build the whole L-layer DNN \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "    \n",
    "    # combine individual layer to form the whole DNN\n",
    "    def combine(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    # print cost during training and evaluation\n",
    "    def print_cost(self,loss_fn, A, Y, epoch_number=-1):\n",
    "        cost = getattr(loss_fn, 'formula')(A, Y)\n",
    "        \n",
    "        # print cost during training\n",
    "        if epoch_number != -1:\n",
    "            print(f'cost of {epoch_number}: {cost}')\n",
    "        \n",
    "        # if epoch_number == -1, then we print cost during evaluation\n",
    "        else:\n",
    "            print(f'cost: {cost}')\n",
    "\n",
    "    # get the derivative of the cost function for the last layer (dA[L])\n",
    "    def get_error_derivative(self, loss_fn, A, Y):\n",
    "        return getattr(loss_fn, 'derivative')(A, Y)\n",
    "    \n",
    "    # call forward pass function for the whole\n",
    "    def forward(self, A):\n",
    "        for layer in self.layers:\n",
    "            A = layer.forward_pass(A)\n",
    "        return A\n",
    "    \n",
    "    # call backward pass function\n",
    "    def backward(self, dA, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            dA = layer.backward_pass(dA, learning_rate)\n",
    "        \n",
    "    # train the DNN model\n",
    "    def fit(self, X, Y, iteration, loss_fn, learning_rate, print_freq=1000):\n",
    "        for i in range(iteration):\n",
    "            \n",
    "            A = self.forward(X)\n",
    "            if i % print_freq == 0: self.print_cost(loss_fn, A, Y, epoch_number=i)        \n",
    "            dA = self.get_error_derivative(loss_fn, A, Y)\n",
    "            self.backward(dA, learning_rate)\n",
    "            \n",
    "        return A\n",
    "    \n",
    "    # predict the result with the trained DNN model\n",
    "    def predict(self, X):\n",
    "        probabilities = self.forward(X)      \n",
    "        predictions = (probabilities >= 0.5) * 1        \n",
    "        return predictions\n",
    "    \n",
    "    # evaluate the performace of the DNN model\n",
    "    def evaluate(self, X, Y, loss_func, dataset_name=\"dataset\", print_cost=False):\n",
    "        Y_hat = self.predict(X)\n",
    "        accuracy = np.average((Y == Y_hat) * 1)\n",
    "        print(f'Accuracy of the {dataset_name}: {accuracy * 100}%')\n",
    "        if print_cost : self.print_cost(loss_fn, self.forward(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost of 0: [0.69588309]\n",
      "cost of 1000: [0.52046877]\n",
      "cost of 2000: [0.14940221]\n",
      "cost of 3000: [0.03375708]\n",
      "cost of 4000: [0.01548739]\n",
      "cost of 5000: [0.00942691]\n",
      "cost of 6000: [0.00661134]\n",
      "cost of 7000: [0.00502246]\n",
      "cost of 8000: [0.0040089]\n",
      "cost of 9000: [0.00331355]\n",
      "Accuracy of the train dataset: 100.0%\n",
      "cost: [0.00281026]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# DATASET CREATION\n",
    "#\n",
    "X_size = 4000\n",
    "ds = CreateDataset()\n",
    "X = ds.create_X(X_size)\n",
    "Y = ds.create_Y(X, X_size)\n",
    "\n",
    "\n",
    "#\n",
    "# NEURAL NETWORK\n",
    "#\n",
    "\n",
    "learning_rate = 0.05\n",
    "loss_fn = LossEntropy()\n",
    "iteration = 10000 # 10000 * 1000 * 4\n",
    "\n",
    "net = Network()\n",
    "net.combine(FCLayer(2, 3, Relu))\n",
    "net.combine(FCLayer(3, 1, Sigmoid))\n",
    "\n",
    "# train the DNN model\n",
    "A = net.fit(X, Y, iteration, loss_fn, learning_rate)\n",
    "\n",
    "# predict a result with a test dataset using the trained DNN model\n",
    "net.evaluate(X, Y, loss_fn, dataset_name=\"train dataset\", print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize dataset and NN Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x64169b0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[0,:], X[1,:], c=Y[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x64730b8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = net.predict(X)\n",
    "plt.scatter(X[0,:], X[1,:], c=Y_pred[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation dataset (XOR) Noisy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation dataset MOONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation dataset CIRCLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
