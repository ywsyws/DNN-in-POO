{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset:\n",
    "    \"\"\" create the 2 XOR datasets, X & Y, for the DNN model \"\"\"\n",
    "    \n",
    "    # create the entry dataset X\n",
    "    def create_X(self, X_size):\n",
    "        self.X = np.random.randint(2, size=(2, X_size))\n",
    "        return self.X\n",
    "    \n",
    "    # create the label dataset Y\n",
    "    def create_Y(self, X):\n",
    "        self.Y = np.sum(X, axis=0)\n",
    "        self.Y[self.Y != 1] = 0\n",
    "        return self.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    \"\"\" the abstract class for all the activation funtion classes\"\"\"\n",
    "    \n",
    "    # the basic formula of the activation function for the forward pass\n",
    "    def formula(self, Z):\n",
    "        raise NotImplementdError\n",
    "    \n",
    "    # to calculate the derivative of the activation function for the backward pass\n",
    "    def derivative(self, input):\n",
    "        raise NotImplementdError\n",
    "    \n",
    "    # to be used to finetune the initialized weight according to the activation function set for the first layer\n",
    "    def heuristic(self, layer_dims):\n",
    "        raise NotImplementdError\n",
    "    \n",
    "\n",
    "class Sigmoid(Activation):\n",
    "    \"\"\" all the functions related to the sigmoid activation function \"\"\"\n",
    "    \n",
    "    # the basic formula of the sigmoid function for the forward pass\n",
    "    def formula(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    # to calculate the derivative of the sigmoid function for the backward pass\n",
    "    def derivative(self, A):\n",
    "        return A * (1 - A)\n",
    "    \n",
    "    # to be used to finetune the initialized weight if sigmoid function is set for the first layer\n",
    "    def heuristic(self, layer_dims):\n",
    "        return np.sqrt(1 / layer_dims)\n",
    "    \n",
    "\n",
    "class Tanh(Activation):\n",
    "    \"\"\" all the functions related to the tanh activation function \"\"\"\n",
    "    \n",
    "    # the basic formula of the tanh function for the forward pass\n",
    "    def formula(self, Z):\n",
    "        return (np.exp(Z) - np.exp(-Z)) / (np.exp(Z) + np.exp(-Z))\n",
    "    \n",
    "    # to calculate the derivative of the tanh function for the backward pass\n",
    "    def derivative(self, A):\n",
    "        return 1 - A**2\n",
    "    \n",
    "    # to be used to finetune the initialized weight if tanh function is set for the first layer\n",
    "    def heuristic(self, layer_dims):\n",
    "        return np.sqrt(1 / layer_dims)\n",
    "    \n",
    "    \n",
    "# class Relu(Activation):\n",
    "#     \"\"\" all the functions related to the relu activation function \"\"\"\n",
    "    \n",
    "#     # the basic formula of the relu function for the forward pass\n",
    "#     def formula(self, Z):\n",
    "#         return (Z > 0) * Z\n",
    "    \n",
    "#     # to calculate the derivative of the relu function for the backward pass\n",
    "#     def derivative(self, Z):\n",
    "#         return 1 - A**2\n",
    "    \n",
    "#     # to be used to finetune the initialized weight if relu function is set for the first layer\n",
    "#     def heuristic(self, layer_dims):\n",
    "#         return np.sqrt(1 / layer_dims)    \n",
    "    \n",
    "#     \"\"\" define activation functions that will be needed in the DNN\"\"\"\n",
    "\n",
    "    \n",
    "#     # relu function and its derivative\n",
    "#     def relu(self, Z, derivative=False):\n",
    "#         if derivative:\n",
    "#             return (Z > 0) * 1\n",
    "#         else:\n",
    "#             return (Z > 0) * Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\" initial class to initialize parameters and ??? \"\"\"\n",
    "    \n",
    "    # initialize parameters\n",
    "    def __init__(self, layer_b4, layer_after, activation, derivative=False):\n",
    "        \n",
    "#         self.L = len(layer_dim)\n",
    "        \n",
    "#         for i in range(1, self.L):\n",
    "#         self.W = np.random.randn(layer_dim[i], layer_dim[i-1])\n",
    "#         self.b = np.zeros(layer_dim[i], 1)\n",
    "\n",
    "        self.W = np.random.randn(layer_after, layer_b4) * 0.01\n",
    "        self.b = np.zeros((layer_after, 1))\n",
    "        print(self.W)\n",
    "        print(self.b)\n",
    "        self.activation =activation\n",
    "        \n",
    "#         if activation == \"sigmoid\":\n",
    "#             self.activation = sigmoid()\n",
    "#         elif activation == \"tanh\":\n",
    "#             self.activation = tanh()\n",
    "#         else:\n",
    "#             self.activation = relu()\n",
    "        \n",
    "    \n",
    "    # calculate forward pass: linear fn (Z = WX + b) and non-linear (A = g(Z))\n",
    "    def forward_pass(self, X):\n",
    "        self.Z = np.dot(self.W, X) + self.b\n",
    "        self.A = self.activation(self.Z)\n",
    "        return self.Z, self.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525741268224334\n",
      "-2\n",
      "0.7071067811865476\n",
      "0.9950547536867306\n",
      "-3\n",
      "0.7071067811865476\n"
     ]
    }
   ],
   "source": [
    "actS = Sigmoid()\n",
    "print(actS.formula(3))\n",
    "print(actS.derivative(2))\n",
    "print(actS.heuristic(2))\n",
    "\n",
    "actT = Tanh()\n",
    "print(actT.formula(3))\n",
    "print(actT.derivative(2))\n",
    "print(actT.heuristic(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02112978  0.00017654]\n",
      " [ 0.00829104  0.01387959]\n",
      " [ 0.00306695  0.0101767 ]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-ab62bc387065>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Z, A = forward_pass(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-189-4142ad15b7f6>\u001b[0m in \u001b[0;36mforward_pass\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActivationFN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-156-6a5aa5c3ef04>\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(self, Z, A, derivative)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# tanh function and its derivative\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'NoneType'"
     ]
    }
   ],
   "source": [
    "layer = Layer(2, 3)\n",
    "Z, A = layer.forward_pass(X)\n",
    "# Z, A = forward_pass(X)\n",
    "print(Z, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0]\n",
      " [1 0 1 1]]\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "ds = CreateDataset()\n",
    "X_size = 4\n",
    "X = ds.create_X(X_size)\n",
    "print(X)\n",
    "Y = ds.create_Y(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0]\n",
      " [1 0 1 1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[1 1 2 1]\n",
      "[False False  True False]\n",
      "[1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "X_size = 4\n",
    "X = np.random.randint(2, size=(2,X_size))\n",
    "print(X)\n",
    "print(type(X))\n",
    "Y = np.sum(X, axis=0)\n",
    "print(Y)\n",
    "print((Y != 1))\n",
    "Y[Y != 1] = 0\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0],\n",
       "       [1, 0, 1, 1]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.relu(X, derivative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87558993, 0.93684569, 0.94847332],\n",
       "       [0.96739116, 0.23928585, 0.85061525],\n",
       "       [0.06319912, 0.46525894, 0.21063519],\n",
       "       [0.9365597 , 0.49253958, 0.06764355]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
